{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c961e8",
   "metadata": {},
   "source": [
    "# resize\n",
    "This script is resize images to 440*440.\n",
    "\n",
    "Change root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def resize_with_padding_256(img, keypoints=None, target_size=440, pad_value=0):\n",
    "    \"\"\"\n",
    "    將圖片等比例縮放，讓長邊變成 target_size，短邊再置中 padding 到 target_size。\n",
    "    若有 keypoints，會同步做相同的縮放 + padding。\n",
    "\n",
    "    參數：\n",
    "        img: 輸入圖片 (H, W, C)\n",
    "        keypoints: (可選) numpy array，shape = (N, 2)，每一列 [x, y]\n",
    "        target_size: 最終輸出邊長（預設 256）\n",
    "        pad_value: padding 顏色 (0=黑)\n",
    "\n",
    "    回傳：\n",
    "        若 keypoints 為 None: img_out\n",
    "        否則: (img_out, kps_out)\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    long_side = max(h, w)\n",
    "    if long_side == 0:\n",
    "        raise ValueError(\"圖片尺寸有問題，高或寬為 0\")\n",
    "\n",
    "    # 等比例縮放比例\n",
    "    scale = float(target_size) / float(long_side)\n",
    "    new_w = max(int(round(w * scale)), 1)\n",
    "    new_h = max(int(round(h * scale)), 1)\n",
    "\n",
    "    # 先 resize\n",
    "    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # 計算 padding（置中）\n",
    "    pad_left = pad_right = pad_top = pad_bottom = 0\n",
    "    if new_w < target_size:\n",
    "        pad_total = target_size - new_w\n",
    "        pad_left = pad_total // 2\n",
    "        pad_right = pad_total - pad_left\n",
    "    if new_h < target_size:\n",
    "        pad_total = target_size - new_h\n",
    "        pad_top = pad_total // 2\n",
    "        pad_bottom = pad_total - pad_top\n",
    "\n",
    "    img_out = cv2.copyMakeBorder(\n",
    "        resized,\n",
    "        pad_top, pad_bottom, pad_left, pad_right,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=pad_value\n",
    "    )\n",
    "\n",
    "    # 處理 keypoints\n",
    "    if keypoints is None:\n",
    "        return img_out\n",
    "\n",
    "    kps = keypoints.astype(np.float32).copy()\n",
    "    x = kps[:, 0]\n",
    "    y = kps[:, 1]\n",
    "\n",
    "    # 先等比例縮放\n",
    "    x_scaled = x * scale\n",
    "    y_scaled = y * scale\n",
    "\n",
    "    # 再加上 padding offset\n",
    "    x_new = x_scaled + pad_left\n",
    "    y_new = y_scaled + pad_top\n",
    "\n",
    "    kps_out = np.stack([x_new, y_new], axis=1)\n",
    "    return img_out, kps_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2fead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_dataset_to_256(\n",
    "    img_dir,\n",
    "    csv_in,\n",
    "    img_out_dir,\n",
    "    csv_out,\n",
    "    target_size=440,\n",
    "    pad_value=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    將某一個資料夾內的所有骨架圖片 + 對應 keypoints\n",
    "    統一轉成 target_size x target_size（等比例縮放 + 置中 padding），\n",
    "    並輸出新的圖片 + CSV。\n",
    "\n",
    "    假設：\n",
    "        - img_dir 裡是骨架圖片（檔名像 000123.png）\n",
    "        - csv_in 裡的 filename 欄位是「原始彩圖檔名」，例如 000123.jpg 或 000123.png\n",
    "        - 兩者用「不含副檔名的 stem」對應\n",
    "    \"\"\"\n",
    "    if not os.path.exists(img_dir):\n",
    "        print(f\"錯誤：找不到圖片目錄 {img_dir}\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(img_out_dir, exist_ok=True)\n",
    "\n",
    "    # 1) 讀 CSV，依 stem 建索引\n",
    "    if not os.path.exists(csv_in):\n",
    "        print(f\"錯誤：找不到 CSV {csv_in}\")\n",
    "        return\n",
    "\n",
    "    with open(csv_in, \"r\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "        if header is None or \"filename\" not in header:\n",
    "            raise ValueError(\"CSV 必須包含 'filename' 欄位\")\n",
    "\n",
    "        cols = header[1:]  # 除去 filename，其餘應為 x,y 成對\n",
    "        if len(cols) % 2 != 0:\n",
    "            raise ValueError(\"除了 filename 之外，CSV 欄位數應該是偶數 (x, y 成對)\")\n",
    "\n",
    "        # 建立 x,y 欄位對\n",
    "        kp_pairs = []\n",
    "        for i in range(0, len(cols), 2):\n",
    "            x_col = cols[i]\n",
    "            y_col = cols[i + 1]\n",
    "            kp_pairs.append((x_col, y_col))\n",
    "\n",
    "        rows_by_stem = {}\n",
    "        for row in reader:\n",
    "            fname = row[\"filename\"]              # e.g. \"000123.jpg\" or \"000123.png\"\n",
    "            stem = os.path.splitext(fname)[0]    # \"000123\"\n",
    "            rows_by_stem[stem] = row\n",
    "\n",
    "    # 2) 準備輸出 CSV\n",
    "    with open(csv_out, \"w\", newline=\"\") as f_out:\n",
    "        writer = csv.DictWriter(f_out, fieldnames=header)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # 3) 找出所有圖片檔\n",
    "        exts = [\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\", \".tif\"]\n",
    "        img_files = [\n",
    "            name for name in os.listdir(img_dir)\n",
    "            if any(name.lower().endswith(ext) for ext in exts)\n",
    "        ]\n",
    "\n",
    "        print(f\"處理資料夾 {img_dir}，共 {len(img_files)} 張圖片\")\n",
    "\n",
    "        for img_name in tqdm(img_files, desc=\"resize to 256\"):\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"警告：無法讀取圖片 {img_name}\")\n",
    "                continue\n",
    "\n",
    "            stem, ext = os.path.splitext(img_name)   # 骨架圖片的 stem\n",
    "\n",
    "            row = rows_by_stem.get(stem)\n",
    "            if row is None:\n",
    "                print(f\"警告：找不到 stem={stem} 對應的 keypoints，略過 keypoints\")\n",
    "                # 只處理圖片，不寫 CSV 行\n",
    "                img_256 = resize_with_padding_256(img, keypoints=None,\n",
    "                                                 target_size=target_size,\n",
    "                                                 pad_value=pad_value)\n",
    "                out_path = os.path.join(img_out_dir, img_name)\n",
    "                cv2.imwrite(out_path, img_256)\n",
    "                continue\n",
    "\n",
    "            # 把 row 的 keypoints 讀成 numpy array\n",
    "            kp_list = []\n",
    "            for x_col, y_col in kp_pairs:\n",
    "                x_val = float(row[x_col])\n",
    "                y_val = float(row[y_col])\n",
    "                kp_list.append([x_val, y_val])\n",
    "            kps = np.array(kp_list, dtype=np.float32)\n",
    "\n",
    "            # 做 resize + padding\n",
    "            img_256, kps_256 = resize_with_padding_256(\n",
    "                img, keypoints=kps,\n",
    "                target_size=target_size,\n",
    "                pad_value=pad_value\n",
    "            )\n",
    "\n",
    "            # 存圖片\n",
    "            out_path = os.path.join(img_out_dir, img_name)\n",
    "            cv2.imwrite(out_path, img_256)\n",
    "\n",
    "            # 存新的 keypoints 一行到 CSV\n",
    "            new_row = dict(row)  # 保留原本的 filename，不動也可以\n",
    "            # 如果你想把 filename 換成骨架圖檔名，可以改：\n",
    "            # new_row[\"filename\"] = img_name\n",
    "\n",
    "            for idx, (x_col, y_col) in enumerate(kp_pairs):\n",
    "                x_new, y_new = kps_256[idx]\n",
    "                new_row[x_col] = float(x_new)\n",
    "                new_row[y_col] = float(y_new)\n",
    "\n",
    "            writer.writerow(new_row)\n",
    "\n",
    "    print(f\"完成：圖片輸出到 {img_out_dir}，CSV 輸出到 {csv_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"\"\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/original_70\",\n",
    "    csv_in=root+\"/sk/original_70.csv\",\n",
    "    img_out_dir=root+\"/resized/original_70\",\n",
    "    csv_out=root+\"/resized/resized_original_70.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/original\",\n",
    "    csv_in=root+\"/sk/original.csv\",\n",
    "    img_out_dir=root+\"/resized/original\",\n",
    "    csv_out=root+\"/resized/resized_original.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/swirl_180\",\n",
    "    csv_in=root+\"/sk/swirl_180.csv\",\n",
    "    img_out_dir=root+\"/resized/swirl_180\",\n",
    "    csv_out=root+\"/resized/resized_swirl_180.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/resize_left_0.7\",\n",
    "    csv_in=root+\"/sk/resize_left_0.7.csv\",\n",
    "    img_out_dir=root+\"/resized/resize_left_0.7\",\n",
    "    csv_out=root+\"/resized/resized_resize_left_0.7.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/resize_left_1.5\",\n",
    "    csv_in=root+\"/sk/resize_left_1.5.csv\",\n",
    "    img_out_dir=root+\"/resized/resize_left_1.5\",\n",
    "    csv_out=root+\"/resized/resized_resize_left_1.5.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/resize_right_0.5\",\n",
    "    csv_in=root+\"/sk/resize_right_0.5.csv\",\n",
    "    img_out_dir=root+\"/resized/resize_right_0.5\",\n",
    "    csv_out=root+\"/resized/resized_resize_right_0.5.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/resize_right_1.3\",\n",
    "    csv_in=root+\"/sk/resize_right_1.3.csv\",\n",
    "    img_out_dir=root+\"/resized/resize_right_1.3\",\n",
    "    csv_out=root+\"/resized/resized_resize_right_1.3.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/resize_upper_0.7\",\n",
    "    csv_in=root+\"/sk/resize_upper_0.7.csv\",\n",
    "    img_out_dir=root+\"/resized/resize_upper_0.7\",\n",
    "    csv_out=root+\"/resized/resized_resize_upper_0.7.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/resize_upper_1.5\",\n",
    "    csv_in=root+\"/sk/resize_upper_1.5.csv\",\n",
    "    img_out_dir=root+\"/resized/resize_upper_1.5\",\n",
    "    csv_out=root+\"/resized/resized_resize_upper_1.5.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/resize_lower_0.5\",\n",
    "    csv_in=root+\"/sk/resize_lower_0.5.csv\",\n",
    "    img_out_dir=root+\"/resized/resize_lower_0.5\",\n",
    "    csv_out=root+\"/resized/resized_resize_lower_0.5.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/resize_lower_1.3\",\n",
    "    csv_in=root+\"/sk/resize_lower_1.3.csv\",\n",
    "    img_out_dir=root+\"/resized/resize_lower_1.3\",\n",
    "    csv_out=root+\"/resized/resized_resize_lower_1.3.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cb86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"\"\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/swirl_15\",\n",
    "    csv_in=root+\"/sk/swirl_15.csv\",\n",
    "    img_out_dir=root+\"/resized/swirl_15\",\n",
    "    csv_out=root+\"/resized/resized_swirl_15.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/swirl_30\",\n",
    "    csv_in=root+\"/sk/swirl_30.csv\",\n",
    "    img_out_dir=root+\"/resized/swirl_30\",\n",
    "    csv_out=root+\"/resized/resized_swirl_30.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/swirl_45\",\n",
    "    csv_in=root+\"/sk/swirl_45.csv\",\n",
    "    img_out_dir=root+\"/resized/swirl_45\",\n",
    "    csv_out=root+\"/resized/resized_swirl_45.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")\n",
    "\n",
    "process_dataset_to_256(\n",
    "    img_dir=root+\"/sk/swirl_60\",\n",
    "    csv_in=root+\"/sk/swirl_60.csv\",\n",
    "    img_out_dir=root+\"/resized/swirl_60\",\n",
    "    csv_out=root+\"/resized/resized_swirl_60.csv\",\n",
    "    target_size=256,\n",
    "    pad_value=0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
